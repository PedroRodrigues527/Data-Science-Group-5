{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from scipy.stats import ttest_ind, f_oneway, ttest_rel, wilcoxon, kruskal, friedmanchisquare, probplot, shapiro\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from Hypothesis import HypothesisTester\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data):\n",
    "    \"\"\"\n",
    "    Standardize the data\n",
    "    :param data: DataFrame\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(data.iloc[:, :-1])  # Exclude the 'Quality' column\n",
    "\n",
    "\n",
    "def normalize_data(std_data):\n",
    "    \"\"\"\n",
    "    Normalize the data\n",
    "    :param data: DataFrame\n",
    "    :return: DataFrame\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(std_data)\n",
    "\n",
    "\n",
    "def creating_features(data):\n",
    "    data['Density'] = data['Weight'] / data['Size']\n",
    "    data['SA Combo'] = data['Acidity'] + data['Sweetness']\n",
    "    data['Texture'] = data['Crunchiness'] + data['Juiciness']\n",
    "    data['Size_Weight'] = data['Size'] + data['Weight']\n",
    "    data['Size_Juiciness'] = data['Size'] + data['Juiciness']\n",
    "    data['Juiciness_Sweetness'] = data['Juiciness'] + data['Sweetness']\n",
    "    data['Juiciness_Ripeness'] = data['Juiciness'] ** 2 / data['Ripeness'] ** 2\n",
    "    data['Size_Weight_Crunchiness'] = data['Size'] * data['Weight'] * data['Crunchiness']\n",
    "    data['Sweetness_Acidity_Juiceness'] = (data['Sweetness'] + data['Acidity'] + data['Juiciness']) / 3\n",
    "    data['Overall_Texture'] = (data['Sweetness'] + data['Crunchiness'] + data['Juiciness'] + data['Ripeness']) / 4\n",
    "    data['JS_SAJ'] = data['Juiciness_Sweetness'] + data['Sweetness_Acidity_Juiceness']\n",
    "    data['Crunchiness_Weight'] = data['Crunchiness'] + data['Weight']\n",
    "    data['SSJ-R Combo'] = data['Size'] + data['Sweetness'] + data['Juiciness'] - data['Ripeness']\n",
    "\n",
    "\n",
    "def plot_histogram(normalized_df):\n",
    "    \"\"\"\n",
    "    Plot histogram for each feature\n",
    "    :param normalized_df: DataFrame\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    num_features = len(normalized_df.columns[:-1])  # Exclude the 'Quality' column\n",
    "    num_rows = (num_features + 3) // 4\n",
    "    num_cols = min(num_features, 4)\n",
    "\n",
    "    plt.figure(figsize=(5 * num_cols, 4 * num_rows))\n",
    "    for i, column in enumerate(normalized_df.columns[:-1], start=1):\n",
    "        plt.subplot(num_rows, num_cols, i)\n",
    "        sns.histplot(normalized_df[column], kde=True)\n",
    "        plt.title(f'Histogram of {column}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_correlation_matrix(normalized_df):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(normalized_df.iloc[:, :-1].corr(), annot=False, cmap='coolwarm', fmt=\".2f\", linewidths=.5, square=True)\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def apply_pca(dataset, n_components=None):\n",
    "    # Apply PCA\n",
    "    pca_model = PCA(n_components=n_components)\n",
    "    pca_result = pca_model.fit_transform(dataset)\n",
    "    return pca_result, pca_model\n",
    "\n",
    "\n",
    "def plot_pca(pca_result, dataset):\n",
    "    # Plot the PCA\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=dataset['Quality'], s=50, alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.title('PCA')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def apply_umap(data_standardized):\n",
    "    # Apply UMAP\n",
    "    reducer = umap.UMAP()\n",
    "    umap_result = reducer.fit_transform(data_standardized)\n",
    "    return umap_result\n",
    "\n",
    "\n",
    "def plot_umap(umap_result, quality_labels):\n",
    "    # Plot the UMAP\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=umap_result[:, 0], y=umap_result[:, 1], hue=quality_labels, palette='viridis', s=50, alpha=0.5)\n",
    "    plt.xlabel('UMAP Component 1')\n",
    "    plt.ylabel('UMAP Component 2')\n",
    "    plt.title('UMAP Projection')\n",
    "    plt.legend(title='Quality')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def unpaired_t_testing(normalized_df):\n",
    "    tester = HypothesisTester()\n",
    "\n",
    "    sample_one = normalized_df[normalized_df['Quality'] == 0].iloc[:, :-1]\n",
    "    sample_two = normalized_df[normalized_df['Quality'] == 1].iloc[:, :-1]\n",
    "\n",
    "    t_stat, p_value = tester.unpaired_t_test(sample_one, sample_two)\n",
    "    print(\"\\nT-testing:\")\n",
    "    print(\"t-statistic:\", t_stat)\n",
    "    print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the apples dataset\n",
    "apples = pd.read_csv('apple_quality_labels.csv')\n",
    "\n",
    "# Remove leading and trailing whitespace from column names\n",
    "apples.columns = apples.columns.str.strip()\n",
    "\n",
    "# Create new features\n",
    "creating_features(apples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for overall distribution before making quality the last column\n",
    "sns.pairplot(apples, hue='Quality', plot_kws={'s': 5})\n",
    "plt.show()\n",
    "\n",
    "# Making 'Quality' the last column\n",
    "cols = list(apples.columns.values)\n",
    "cols.pop(cols.index('Quality'))\n",
    "apples = apples[cols + ['Quality']]\n",
    "\n",
    "# Pairplot for overall distribution after standardization and normalization\n",
    "sns.pairplot(normalized_df, hue='Quality', plot_kws={'s': 5})\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram for each feature\n",
    "plot_histogram(normalized_df)\n",
    "\n",
    "# Correlation matrix\n",
    "plot_correlation_matrix(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Standardization and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "standardized_data = standardize_data(apples)\n",
    "\n",
    "# Normalize the data\n",
    "normalized_data = normalize_data(standardized_data)\n",
    "\n",
    "# Convert the normalized data back to a DataFrame\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=apples.columns[:-1])\n",
    "\n",
    "# Add the 'Quality' column back to the DataFrame\n",
    "normalized_df['Quality'] = apples['Quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "pca_result, pca_model = apply_pca(normalized_df, n_components=2)\n",
    "\n",
    "# Plot PCA\n",
    "plot_pca(pca_result, normalized_df)\n",
    "\n",
    "# Apply UMAP\n",
    "umap_result = apply_umap(standardized_data)\n",
    "\n",
    "# Plot UMAP\n",
    "plot_umap(umap_result, apples['Quality'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-testing\n",
    "unpaired_t_testing(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
